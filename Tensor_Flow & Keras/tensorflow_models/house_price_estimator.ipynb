{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.23) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "'''required moduels and functions'''\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housing_median_age  total_rooms  total_bedrooms  population  households  \\\n",
       "0                41.0        880.0           129.0       322.0       126.0   \n",
       "1                21.0       7099.0          1106.0      2401.0      1138.0   \n",
       "2                52.0       1467.0           190.0       496.0       177.0   \n",
       "3                52.0       1274.0           235.0       558.0       219.0   \n",
       "4                52.0       1627.0           280.0       565.0       259.0   \n",
       "\n",
       "   median_income  median_house_value  \n",
       "0         8.3252            452600.0  \n",
       "1         8.3014            358500.0  \n",
       "2         7.2574            352100.0  \n",
       "3         5.6431            341300.0  \n",
       "4         3.8462            342200.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''houses data set'''\n",
    "\n",
    "houses = pd.read_csv('data/cali_housing.csv').iloc[:,2:-1]\n",
    "houses = houses.dropna()\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# so once I have the data I need to set up the columns for the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val = houses['median_house_value']\n",
    "x_data = houses.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test data split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_val, test_size=0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31372549, 0.02853655, 0.02886406, 0.01541523, 0.03354711,\n",
       "        0.36173294],\n",
       "       [0.56862745, 0.09957271, 0.08504035, 0.03719275, 0.08929452,\n",
       "        0.41804941],\n",
       "       [0.74509804, 0.02914696, 0.05384854, 0.03245607, 0.05459628,\n",
       "        0.11839837],\n",
       "       ...,\n",
       "       [0.52941176, 0.04504298, 0.04298572, 0.02245018, 0.0440717 ,\n",
       "        0.30049241],\n",
       "       [0.33333333, 0.05720026, 0.07898821, 0.02884049, 0.06051636,\n",
       "        0.12377071],\n",
       "       [0.7254902 , 0.03652271, 0.04795158, 0.02174949, 0.04505838,\n",
       "        0.05717163]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling the data set\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit_transform(X_train)\n",
    "scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housing_median_age', 'total_rooms', 'total_bedrooms', 'population',\n",
       "       'households', 'median_income', 'median_house_value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input columns for the neural network\n",
    "\n",
    "median = tf.feature_column.numeric_column('housing_median_age')\n",
    "rooms = tf.feature_column.numeric_column('total_rooms')\n",
    "bedrooms = tf.feature_column.numeric_column('total_bedrooms')\n",
    "popu = tf.feature_column.numeric_column('population')\n",
    "hh = tf.feature_column.numeric_column('households')\n",
    "inc = tf.feature_column.numeric_column('median_income')\n",
    "\n",
    "feat_cols = [median, rooms, bedrooms, popu, hh, inc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input function for the neural net\n",
    "\n",
    "train_inp_fnc = tf.estimator.inputs.pandas_input_fn(x=X_train ,y=y_train, shuffle=True, batch_size=10, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DNN REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpf3kde3iv\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_device_fn': None, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3421b25a58>, '_save_checkpoints_secs': 600, '_protocol': None, '_tf_random_seed': None, '_is_chief': True, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_service': None, '_save_checkpoints_steps': None, '_train_distribute': None, '_task_type': 'worker', '_evaluation_master': '', '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmpf3kde3iv', '_master': '', '_task_id': 0, '_global_id_in_cluster': 0, '_experimental_distribute': None}\n"
     ]
    }
   ],
   "source": [
    "dnn_reg = tf.estimator.DNNRegressor(hidden_units=[10,20,20,20,20,10], feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpf3kde3iv/model.ckpt.\n",
      "INFO:tensorflow:loss = 55109990000000.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 70.8032\n",
      "INFO:tensorflow:loss = 26575987000000.0, step = 101 (1.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.0969\n",
      "INFO:tensorflow:loss = 17215894000000.0, step = 201 (1.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.997\n",
      "INFO:tensorflow:loss = 12998400000000.0, step = 301 (1.815 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.4094\n",
      "INFO:tensorflow:loss = 11399105000000.0, step = 401 (1.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.1303\n",
      "INFO:tensorflow:loss = 11897540000000.0, step = 501 (1.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.0843\n",
      "INFO:tensorflow:loss = 11090184000000.0, step = 601 (1.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.4946\n",
      "INFO:tensorflow:loss = 9814822000000.0, step = 701 (1.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.6977\n",
      "INFO:tensorflow:loss = 9108754000000.0, step = 801 (1.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.1416\n",
      "INFO:tensorflow:loss = 10932635000000.0, step = 901 (1.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.8385\n",
      "INFO:tensorflow:loss = 9502948000000.0, step = 1001 (1.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.8248\n",
      "INFO:tensorflow:loss = 9444437000000.0, step = 1101 (1.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.3631\n",
      "INFO:tensorflow:loss = 9236294000000.0, step = 1201 (1.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.4698\n",
      "INFO:tensorflow:loss = 9003880000000.0, step = 1301 (1.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.7965\n",
      "INFO:tensorflow:loss = 8877546000000.0, step = 1401 (1.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.6132\n",
      "INFO:tensorflow:loss = 7915880600000.0, step = 1501 (1.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.8912\n",
      "INFO:tensorflow:loss = 8365266700000.0, step = 1601 (1.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.7802\n",
      "INFO:tensorflow:loss = 7483409000000.0, step = 1701 (1.566 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.0941\n",
      "INFO:tensorflow:loss = 7760126000000.0, step = 1801 (1.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.655\n",
      "INFO:tensorflow:loss = 8870969000000.0, step = 1901 (1.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.7201\n",
      "INFO:tensorflow:loss = 8035721300000.0, step = 2001 (1.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.9271\n",
      "INFO:tensorflow:loss = 7847282700000.0, step = 2101 (1.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.8838\n",
      "INFO:tensorflow:loss = 7216517600000.0, step = 2201 (1.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.0683\n",
      "INFO:tensorflow:loss = 7937060000000.0, step = 2301 (1.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0713\n",
      "INFO:tensorflow:loss = 6994392500000.0, step = 2401 (1.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.1343\n",
      "INFO:tensorflow:loss = 7130668600000.0, step = 2501 (1.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.3735\n",
      "INFO:tensorflow:loss = 7742803700000.0, step = 2601 (1.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.4354\n",
      "INFO:tensorflow:loss = 7074974000000.0, step = 2701 (1.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.6497\n",
      "INFO:tensorflow:loss = 9092941000000.0, step = 2801 (1.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.6739\n",
      "INFO:tensorflow:loss = 6745159000000.0, step = 2901 (1.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.2602\n",
      "INFO:tensorflow:loss = 7716097000000.0, step = 3001 (1.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.1647\n",
      "INFO:tensorflow:loss = 7576913700000.0, step = 3101 (1.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.3263\n",
      "INFO:tensorflow:loss = 7521225400000.0, step = 3201 (1.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.3586\n",
      "INFO:tensorflow:loss = 6631137000000.0, step = 3301 (1.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.1824\n",
      "INFO:tensorflow:loss = 7402820700000.0, step = 3401 (1.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.4365\n",
      "INFO:tensorflow:loss = 7065347000000.0, step = 3501 (1.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.3094\n",
      "INFO:tensorflow:loss = 7568551300000.0, step = 3601 (1.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.5212\n",
      "INFO:tensorflow:loss = 6625406000000.0, step = 3701 (1.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6964\n",
      "INFO:tensorflow:loss = 6542893500000.0, step = 3801 (1.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.2958\n",
      "INFO:tensorflow:loss = 6752418000000.0, step = 3901 (1.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.3485\n",
      "INFO:tensorflow:loss = 6595333300000.0, step = 4001 (1.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.2291\n",
      "INFO:tensorflow:loss = 6230109000000.0, step = 4101 (1.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.32\n",
      "INFO:tensorflow:loss = 7005696700000.0, step = 4201 (1.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2676\n",
      "INFO:tensorflow:loss = 6297971000000.0, step = 4301 (1.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.5331\n",
      "INFO:tensorflow:loss = 6639752600000.0, step = 4401 (1.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.8607\n",
      "INFO:tensorflow:loss = 5858813500000.0, step = 4501 (1.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.5312\n",
      "INFO:tensorflow:loss = 5640991000000.0, step = 4601 (1.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.6862\n",
      "INFO:tensorflow:loss = 5872148300000.0, step = 4701 (1.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.4527\n",
      "INFO:tensorflow:loss = 6009336600000.0, step = 4801 (1.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.8736\n",
      "INFO:tensorflow:loss = 5496170000000.0, step = 4901 (1.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.629\n",
      "INFO:tensorflow:loss = 5849733000000.0, step = 5001 (1.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.6134\n",
      "INFO:tensorflow:loss = 5523981000000.0, step = 5101 (1.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.2929\n",
      "INFO:tensorflow:loss = 6356626000000.0, step = 5201 (1.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.7413\n",
      "INFO:tensorflow:loss = 5735741700000.0, step = 5301 (1.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.2998\n",
      "INFO:tensorflow:loss = 5802279600000.0, step = 5401 (1.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2767\n",
      "INFO:tensorflow:loss = 5774990000000.0, step = 5501 (1.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.1309\n",
      "INFO:tensorflow:loss = 5911242300000.0, step = 5601 (1.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.525\n",
      "INFO:tensorflow:loss = 5911266500000.0, step = 5701 (1.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.9856\n",
      "INFO:tensorflow:loss = 5247953000000.0, step = 5801 (1.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.1116\n",
      "INFO:tensorflow:loss = 6017633000000.0, step = 5901 (1.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.3331\n",
      "INFO:tensorflow:loss = 5875510000000.0, step = 6001 (1.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.3566\n",
      "INFO:tensorflow:loss = 5616872500000.0, step = 6101 (1.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.9711\n",
      "INFO:tensorflow:loss = 7078336000000.0, step = 6201 (1.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.8501\n",
      "INFO:tensorflow:loss = 6482990000000.0, step = 6301 (1.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.7142\n",
      "INFO:tensorflow:loss = 5861322000000.0, step = 6401 (1.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.3817\n",
      "INFO:tensorflow:loss = 6363733300000.0, step = 6501 (1.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.9723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5734266000000.0, step = 6601 (1.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.8365\n",
      "INFO:tensorflow:loss = 5916750500000.0, step = 6701 (1.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.724\n",
      "INFO:tensorflow:loss = 6001540500000.0, step = 6801 (1.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.2108\n",
      "INFO:tensorflow:loss = 5288485000000.0, step = 6901 (1.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.3778\n",
      "INFO:tensorflow:loss = 5734058000000.0, step = 7001 (1.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.1846\n",
      "INFO:tensorflow:loss = 5474315400000.0, step = 7101 (1.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.6925\n",
      "INFO:tensorflow:loss = 6082330600000.0, step = 7201 (1.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.7359\n",
      "INFO:tensorflow:loss = 5665271600000.0, step = 7301 (1.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.0653\n",
      "INFO:tensorflow:loss = 5609524000000.0, step = 7401 (1.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2761\n",
      "INFO:tensorflow:loss = 5653149000000.0, step = 7501 (1.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.6537\n",
      "INFO:tensorflow:loss = 5017858700000.0, step = 7601 (1.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.5125\n",
      "INFO:tensorflow:loss = 5815176500000.0, step = 7701 (1.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2572\n",
      "INFO:tensorflow:loss = 6045979000000.0, step = 7801 (1.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.7068\n",
      "INFO:tensorflow:loss = 5768967400000.0, step = 7901 (1.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.675\n",
      "INFO:tensorflow:loss = 5784517000000.0, step = 8001 (1.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.5281\n",
      "INFO:tensorflow:loss = 5192233000000.0, step = 8101 (1.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.8288\n",
      "INFO:tensorflow:loss = 5716610400000.0, step = 8201 (1.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.0301\n",
      "INFO:tensorflow:loss = 5640964500000.0, step = 8301 (1.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.5815\n",
      "INFO:tensorflow:loss = 5025780700000.0, step = 8401 (1.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.2335\n",
      "INFO:tensorflow:loss = 5342780000000.0, step = 8501 (1.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.5989\n",
      "INFO:tensorflow:loss = 4882116400000.0, step = 8601 (1.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.1174\n",
      "INFO:tensorflow:loss = 5274252300000.0, step = 8701 (1.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.7787\n",
      "INFO:tensorflow:loss = 5202114500000.0, step = 8801 (1.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.9228\n",
      "INFO:tensorflow:loss = 5826649500000.0, step = 8901 (1.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.3686\n",
      "INFO:tensorflow:loss = 4830105000000.0, step = 9001 (1.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.9729\n",
      "INFO:tensorflow:loss = 5960013700000.0, step = 9101 (1.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.9284\n",
      "INFO:tensorflow:loss = 4838431700000.0, step = 9201 (1.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.4003\n",
      "INFO:tensorflow:loss = 4993496000000.0, step = 9301 (1.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.3896\n",
      "INFO:tensorflow:loss = 5550567300000.0, step = 9401 (1.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.2868\n",
      "INFO:tensorflow:loss = 5342802000000.0, step = 9501 (1.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.2394\n",
      "INFO:tensorflow:loss = 4887776600000.0, step = 9601 (1.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.1693\n",
      "INFO:tensorflow:loss = 5405702000000.0, step = 9701 (1.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0242\n",
      "INFO:tensorflow:loss = 4967509300000.0, step = 9801 (1.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.7268\n",
      "INFO:tensorflow:loss = 5276399000000.0, step = 9901 (1.476 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmpf3kde3iv/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5424118500000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x7f3421b25908>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_reg.train(train_inp_fnc, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-30-01:36:27\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpf3kde3iv/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-30-01:36:29\n",
      "INFO:tensorflow:Saving dict for global step 10000: average_loss = 5391969300.0, global_step = 10000, label/mean = 207961.75, loss = 53919695000.0, prediction/mean = 209873.61\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmpf3kde3iv/model.ckpt-10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_loss': 5391969300.0,\n",
       " 'global_step': 10000,\n",
       " 'label/mean': 207961.75,\n",
       " 'loss': 53919695000.0,\n",
       " 'prediction/mean': 209873.61}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating the DNN regression model\n",
    "\n",
    "eval_inp = tf.estimator.inputs.pandas_input_fn(x=X_test, y=y_test, num_epochs=1, shuffle=False, batch_size=10)\n",
    "dnn_reg.evaluate(eval_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_inp =tf.estimator.inputs.pandas_input_fn(x=X_test, batch_size=10, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpf3kde3iv/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "pred_val = list(dnn_reg.predict(pred_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_pred=[]\n",
    "for i in pred_val:\n",
    "    final_pred.append(i['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73430.04356481417"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, final_pred)**0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
